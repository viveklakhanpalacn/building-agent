{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fdd0bcb",
   "metadata": {},
   "source": [
    "# [STARTER] Udaplay Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325b035",
   "metadata": {},
   "source": [
    "## Part 02 - Agent\n",
    "\n",
    "In this part of the project, you'll use your VectorDB to be part of your Agent as a tool.\n",
    "\n",
    "You're building UdaPlay, an AI Research Agent for the video game industry. The agent will:\n",
    "1. Answer questions using internal knowledge (RAG)\n",
    "2. Search the web when needed\n",
    "3. Maintain conversation state\n",
    "4. Return structured outputs\n",
    "5. Store useful information for future use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b42de90",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a963d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd10c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from typing import List, Dict, TypedDict, Optional\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "\n",
    "from lib.agents import Agent\n",
    "from lib.llm import LLM\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage, AIMessage, BaseMessage\n",
    "from lib.tooling import tool\n",
    "from lib.vector_db import VectorStoreManager\n",
    "from lib.memory import LongTermMemory, MemoryFragment, MemorySearchResult\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination, Run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e465d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "CHROMA_OPENAI_API_KEY = os.getenv(\"CHROMA_OPENAI_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f6a6260",
   "metadata": {},
   "source": [
    "### Setup ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce364221",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path=\"chromadb\")\n",
    "embedding_fn = embedding_functions.OpenAIEmbeddingFunction(api_key=CHROMA_OPENAI_API_KEY)\n",
    "collection = chroma_client.get_collection(name=\"udaplay\", embedding_function=embedding_fn)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7667b35",
   "metadata": {},
   "source": [
    "### Setup Tavily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cf0cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_client = TavilyClient(api_key=TAVILY_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de4729",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab2dac",
   "metadata": {},
   "source": [
    "Build at least 3 tools:\n",
    "- retrieve_game: To search the vector DB\n",
    "- evaluate_retrieval: To assess the retrieval performance\n",
    "- game_web_search: If no good, search the web\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4f14cd",
   "metadata": {},
   "source": [
    "#### Retrieve Game Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_game(query: str):\n",
    "    \"\"\"\n",
    "    Semantic search: Finds most results in the vector DB\n",
    "    args:\n",
    "    - query: a question about game industry. \n",
    "\n",
    "    Returns results as list. Each element contains:\n",
    "    - Platform: like Game Boy, Playstation 5, Xbox 360...)\n",
    "    - Name: Name of the Game\n",
    "    - YearOfRelease: Year when that game was released for that platform\n",
    "    - Description: Additional details about the game\n",
    "    \"\"\"\n",
    "\n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=5\n",
    "    )\n",
    "\n",
    "    docs = results['documents'][0]\n",
    "    metadatas = results['metadatas'][0]\n",
    "    \n",
    "    retrieved = []\n",
    "    for doc, meta in zip(docs, metadatas):\n",
    "        retrieved.append({\n",
    "            \"Name\": meta.get(\"Name\"),\n",
    "            \"Platform\": meta.get(\"Platform\"),\n",
    "            \"YearOfRelease\": meta.get(\"YearOfRelease\"),\n",
    "            \"Description\": meta.get(\"Description\")\n",
    "        })\n",
    "    return str(retrieved)\n",
    "\n",
    "retrieve_game_tool = tool(\n",
    "    func=retrieve_game,\n",
    "    name=\"retrieve_game\",\n",
    "    description=\"Search the video game information in the local database.\"\n",
    ")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910dc945",
   "metadata": {},
   "source": [
    "#### Evaluate Retrieval Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9d014b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_retrieval(question: str, retrieved_docs: str):\n",
    "    \"\"\"\n",
    "    Based on the user's question and on the list of retrieved documents, \n",
    "    it will analyze the usability of the documents to respond to that question. \n",
    "    args: \n",
    "    - question: original question from user\n",
    "    - retrieved_docs: retrieved documents most similar to the user query in the Vector Database\n",
    "    \n",
    "    The result includes:\n",
    "    - useful: whether the documents are useful to answer the question\n",
    "    - description: description about the evaluation result\n",
    "    \"\"\"\n",
    "\n",
    "    # Use a separate LLM call to evaluate\n",
    "    llm = LLM(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        api_key=OPENAI_API_KEY\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Your task is to evaluate if the documents are enough to respond the query.\n",
    "    Give a detailed explanation, so it's possible to take an action to accept it or not.\n",
    "    Question: {question}\n",
    "    Retrieved: {retrieved_docs}\n",
    "\n",
    "    Return a JSON with \"useful\" (boolean) and \"description\" (string).\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke([\n",
    "        UserMessage(content=prompt)\n",
    "    ])\n",
    "    return response.content\n",
    "\n",
    "evaluate_retrieval_tool = tool(\n",
    "    func=evaluate_retrieval,\n",
    "    name=\"evaluate_retrieval\",\n",
    "    description=\"Evaluate if retrieved documents are sufficient \"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7935a26",
   "metadata": {},
   "source": [
    "#### Game Web Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad698aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_web_search(query: str, search_depth: str = \"advanced\"):\n",
    "    \"\"\"\n",
    "    Search the web using Tavily API\n",
    "    args:\n",
    "        query (str): Search query\n",
    "        search_depth (str): Type of search - 'basic' or 'advanced' (default: advanced)\n",
    "    \"\"\"\n",
    "\n",
    "    # Perform the search\n",
    "    search_result = tavily_client.search(\n",
    "        query=query,\n",
    "        saerch_depth=search_depth,\n",
    "        include_answer=True,\n",
    "        include_raw_content=False,\n",
    "        include_images=False\n",
    "    )\n",
    "\n",
    "    # Format the results\n",
    "    formatted_results = {\n",
    "        \"answer\": search_result.get(\"answer\", \"\"),\n",
    "        \"results\": search_result.get(\"results\", []),\n",
    "        \"search_metadata\": {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"query\": query\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return str(formatted_results)\n",
    "\n",
    "game_web_search_tool = tool(\n",
    "    func=game_web_search,\n",
    "    name=\"game_web_search\",\n",
    "    description=\"Search the web for game information when local database is insufficient.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df844b3b",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c56281",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [retrieve_game_tool, evaluate_retrieval_tool, game_web_search_tool]\n",
    "agent = Agent(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    instructions=(\n",
    "        \"You are UdaPlay, an AI Research Agent for the video game industry. \"\n",
    "        \"Your goal is to answer user questions comprehensively. \"\n",
    "        \"1. First, search your internal memory (vector DB) using `retrieve_game`. \"\n",
    "        \"2. Evaluate if the retrieved info is sufficient using `evaluate_retrieval`. \"\n",
    "        \"3. If not sufficient, search the web using `game_web_search`. \"\n",
    "        \"4. Always cite your sources. If you found it in the local database, cite 'Local DB'. \"\n",
    "        \"If you found it on the web, cite the URL or 'Web Search'. \"\n",
    "        \"5. Structure your answer clearly.\"\n",
    "    ),\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec23893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print agent trace\n",
    "def print_agent_response(response):\n",
    "    messages = response.get_final_state()[\"messages\"]\n",
    "    \n",
    "    print(\"AGENT Trace\")\n",
    "    print(\"===============\")\n",
    "    for msg in messages:\n",
    "        role = msg.role.upper()\n",
    "        if role == \"SYSTEM\":\n",
    "            continue\n",
    "        print(f\"\\n[{role}]\")\n",
    "        # tool Calls (in AI message)\n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "            for tc in msg.tool_calls:\n",
    "                print(f\"\\n Tool Call: {tc.function.name}({tc.function.arguments})\")\n",
    "        # Content\n",
    "        if msg.content:  \n",
    "            print(f\"{msg.content}\")\n",
    "    print(\"===============\")\n",
    "\n",
    "# helper method to run query\n",
    "def run_query(query, session_id):\n",
    "    print(f\"\\n --- User Query: {query} ---\")\n",
    "    response = agent.invoke(\n",
    "        query=query,\n",
    "        session_id=session_id\n",
    "    )\n",
    "    print_agent_response(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf231aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Queries\n",
    "run_query('Which one was the first 3D platformer Mario Game?', \"first_session\")\n",
    "run_query('When was it released?', \"first_session\")\n",
    "run_query('Was Mortal Kombat X realeased for Playstation 5?', \"session_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a55081",
   "metadata": {},
   "source": [
    "### (Optional) Advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb83fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_manager = VectorStoreManager(openai_api_key=OPENAI_API_KEY)\n",
    "ltm = LongTermMemory(vector_store_manager)\n",
    "llm = LLM(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e6ec52f6",
   "metadata": {},
   "source": [
    "### AGENT STATE - Define Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23df2736",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    input_query: str\n",
    "    user_id: str\n",
    "    context_games: Optional[str]\n",
    "    context_memory: Optional[str]\n",
    "    context_web: Optional[str]\n",
    "    is_sufficient: bool\n",
    "    final_answer: str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67db04a2",
   "metadata": {},
   "source": [
    "### Define Steps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e5b4e50",
   "metadata": {},
   "source": [
    "### Step: Retrieve memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4b7af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_memory_step(state: AgentState) -> AgentState:\n",
    "    \"\"\"Check Long Term Memory for user context\"\"\"\n",
    "    print(f\"   [Step] Check Long Term Memory for user context...{state[\"input_query\"],}\")\n",
    "    print(f\"   [Step] Checking Memory for user: {state['user_id']}\")\n",
    "    results = ltm.search(\n",
    "        query_text=state[\"input_query\"],\n",
    "        owner=state[\"user_id\"],\n",
    "        limit=2\n",
    "    )\n",
    "    memories = [f\"- {m.content}\" for m in results.fragments]\n",
    "    print(f\"   [Step] prepare return info context memory... {memories}\")\n",
    "    context_str = \"\\n\".join(memories) if memories else \"No relevant personal memories found.\"\n",
    "    print(f\"   [Step] prepare return info context memory...\")\n",
    "    return {\n",
    "        **state,\n",
    "        \"context_memory\": context_str\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70f4f9fb",
   "metadata": {},
   "source": [
    "### Step: Retreive game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7088d830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_game_step(state: AgentState) -> AgentState:\n",
    "    print(f\"   [step] Retrieving Game Info...\")\n",
    "    results = collection.query(\n",
    "        query_texts=[state[\"input_query\"]],\n",
    "        n_results=3\n",
    "    )\n",
    "    \n",
    "    docs = results['documents'][0]\n",
    "    metadatas = results['metadatas'][0]\n",
    "        \n",
    "    game_info = []\n",
    "    for doc, meta in zip(docs, metadatas):\n",
    "        name = str(meta.get('Name', 'Unknown'))\n",
    "        platform = str(meta.get('Platform', 'Unknown'))\n",
    "        year = str(meta.get('YearOfRelease', 'Unknown'))\n",
    "        doc_str = str(doc)\n",
    "        \n",
    "        info = f\"Game: {name} ({platform}, {year})\\nDetails: {doc_str}\"\n",
    "        game_info.append(info)\n",
    "\n",
    "    context_str = \"\\n---\\n\".join(game_info)\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"context_games\": context_str\n",
    "    }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82824f8a",
   "metadata": {},
   "source": [
    "### Step: Evaluate state "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "655c5d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_step(state: AgentState) -> AgentState:\n",
    "    \"\"\"Evaluate if retrieved info is sufficient\"\"\"\n",
    "    print(f\"   [Step] Evaluating Context....\")\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    User Query: {state['input_query']}\n",
    "\n",
    "    Retrieved Game Info:\n",
    "    {state['context_games']}\n",
    "\n",
    "    Retrieved User Memory:\n",
    "    {state['context_memory']}\n",
    "    \n",
    "    Is this information sufficient to answer the user's query comfortably? \n",
    "    If the user asks about a game not listed here, or specific details missing here, answer NO.\n",
    "    \n",
    "    Respond with ONLY 'YES' or 'NO'.\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke([\n",
    "        UserMessage(content=prompt)\n",
    "    ])\n",
    "    decision = response.content.strip().upper()\n",
    "\n",
    "    is_sufficient = \"YES\" in decision\n",
    "    print(f\"   [Step] Evaluation Result: {is_sufficient}\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"is_sufficient\": is_sufficient\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73301689",
   "metadata": {},
   "source": [
    "### Step: Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "751c6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search_step(state: AgentState) -> AgentState:\n",
    "    \"\"\"Search web if local info is insufficient\"\"\"\n",
    "    print(f\"   [Step] Searching Web...\")\n",
    "\n",
    "    try:\n",
    "        # Perform the search\n",
    "        search_result = tavily_client.search(\n",
    "            query=state['input_query'],\n",
    "            saerch_depth=\"advanced\",\n",
    "            include_answer=True,\n",
    "            include_raw_content=False,\n",
    "            include_images=False\n",
    "        )\n",
    "\n",
    "        # Format the results\n",
    "        results = search_result.get(\"results\", [])\n",
    "        web_context = \"\\n\".join([f\"- {r['content']}\" for r in results[:3]])\n",
    "    except Exception as e:\n",
    "        web_context = f\"Web search failed: {e}\"    \n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"context_web\": web_context\n",
    "    }\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85126e11",
   "metadata": {},
   "source": [
    "### Step: Generate answer  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5353c498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer_step(state: AgentState) -> AgentState:\n",
    "    \"\"\"Generate final response using all available context\"\"\"\n",
    "    print(f\"   [Step] Generating Answer...\")\n",
    "    \n",
    "    # Construct context based on what we have\n",
    "    context_parts = []\n",
    "    if state[\"context_memory\"]:\n",
    "        context_parts.append(f\"User Context:\\n{state['context_memory']}\")\n",
    "    \n",
    "    if state[\"context_games\"]:\n",
    "        context_parts.append(f\"Game Database Info:\\n{state['context_games']}\")\n",
    "        \n",
    "    if state.get(\"context_web\"):\n",
    "        context_parts.append(f\"Web Search Results:\\n{state['context_web']}\")\n",
    "        \n",
    "    full_context = \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    system_prompt = \"You are UdaPlay, an expert video game assistant. Answer the user query using the provided context.\"\n",
    "    user_prompt = f\"\"\"\n",
    "    Context:\n",
    "    {full_context}\n",
    "    \n",
    "    Query: {state['input_query']}\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([\n",
    "        SystemMessage(content=system_prompt),\n",
    "        UserMessage(content=user_prompt)\n",
    "    ])\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"final_answer\": response.content\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bf4d9b0",
   "metadata": {},
   "source": [
    "### Step: Memorize step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a714a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memorize_step(state: AgentState) -> AgentState:\n",
    "    \"\"\"Extract and save new user preferences if found\"\"\"\n",
    "    print(f\"   [Step] Checking for new memories...\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Analyze the user's query for any explicit user preferences or facts about themselves (e.g., \"I like RPGs\", \"I own a PS5\").\n",
    "    Igore questions or general statements.\n",
    "    \n",
    "    Query: {state['input_query']}\n",
    "    \n",
    "    If a preference is found, output the preference content. \n",
    "    If nothing to memorize, output 'SKIP'.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = llm.invoke([UserMessage(content=prompt)])\n",
    "    content = response.content.strip()\n",
    "    \n",
    "    if content != \"SKIP\":\n",
    "        ltm.register(MemoryFragment(content=content, owner=state['user_id']))\n",
    "        print(f\"   [Memory] Saved: {content}\")\n",
    "        \n",
    "    return state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "667e1097",
   "metadata": {},
   "source": [
    "### Build & Connect State Machine Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c36a745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_agent_workflow():\n",
    "    workflow = StateMachine[AgentState](AgentState)\n",
    "    \n",
    "    # Steps\n",
    "    entry = EntryPoint[AgentState]()\n",
    "    s_memory = Step[AgentState](\"retrieve_memory\", retrieve_memory_step)\n",
    "    s_game = Step[AgentState](\"retrieve_game\", retrieve_game_step)\n",
    "    s_eval = Step[AgentState](\"evaluate\", evaluate_step)\n",
    "    s_web = Step[AgentState](\"web_search\", web_search_step)\n",
    "    s_gen = Step[AgentState](\"generate\", generate_answer_step)\n",
    "    s_memo = Step[AgentState](\"memorize\", memorize_step) # Running this after gen\n",
    "    term = Termination[AgentState]()\n",
    "    \n",
    "    workflow.add_steps([entry, s_memory, s_game, s_eval, s_web, s_gen, s_memo, term])\n",
    "    \n",
    "    # Transitions\n",
    "    \n",
    "    # Entry -> Memory\n",
    "    workflow.connect(entry, s_memory)\n",
    "    \n",
    "    # Memory -> Game Retrieval\n",
    "    workflow.connect(s_memory, s_game)\n",
    "    \n",
    "    # Game -> Eval\n",
    "    workflow.connect(s_game, s_eval)\n",
    "    \n",
    "    # Eval -> Web OR Generate using condition logic\n",
    "    def check_eval(state: AgentState):\n",
    "        if state[\"is_sufficient\"]:\n",
    "            return s_gen\n",
    "        else:\n",
    "            return s_web\n",
    "            \n",
    "    workflow.connect(s_eval, [s_gen, s_web], check_eval)\n",
    "    \n",
    "    # Web -> Generate\n",
    "    workflow.connect(s_web, s_gen)\n",
    "    \n",
    "    # Generate -> Memorize\n",
    "    workflow.connect(s_gen, s_memo)\n",
    "    \n",
    "    # Memorize -> Termination\n",
    "    workflow.connect(s_memo, term)\n",
    "    \n",
    "    return workflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5453f9ff",
   "metadata": {},
   "source": [
    "### Run the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f48b3ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = build_agent_workflow()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a9d09cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== RUN 1: Preference Sharing ===\n",
      "[StateMachine] Starting: __entry__\n",
      "   [Step] Check Long Term Memory for user context...('I love open-world games like GTA.',)\n",
      "   [Step] Checking Memory for user: test_user_1\n",
      "   [Step] prepare return info context memory... ['- open-world games like GTA']\n",
      "   [Step] prepare return info context memory...\n",
      "[StateMachine] Executing step: retrieve_memory\n",
      "   [step] Retrieving Game Info...\n",
      "[StateMachine] Executing step: retrieve_game\n",
      "   [Step] Evaluating Context....\n",
      "   [Step] Evaluation Result: True\n",
      "[StateMachine] Executing step: evaluate\n",
      "   [Step] Generating Answer...\n",
      "[StateMachine] Executing step: generate\n",
      "   [Step] Checking for new memories...\n",
      "   [Memory] Saved: open-world games like GTA\n",
      "[StateMachine] Executing step: memorize\n",
      "[StateMachine] Terminating: __termination__\n",
      "Final Answer: If you love open-world games like Grand Theft Auto, you might enjoy **Marvel's Spider-Man**. It's an open-world superhero game that allows you to explore New York City while taking on various villains, similar to the expansive environments and engaging narratives found in GTA games. The freedom to roam and the dynamic gameplay should resonate well with your interests!\n"
     ]
    }
   ],
   "source": [
    "# Session 1: User states preference\n",
    "print(\"\\n\\n=== RUN 1: Preference Sharing ===\")\n",
    "initial_state = {\n",
    "    \"input_query\": \"I love open-world games like GTA.\",\n",
    "    \"user_id\": \"test_user_1\",\n",
    "    \"context_games\": None,\n",
    "    \"context_memory\": None,\n",
    "    \"context_web\": None,\n",
    "    \"is_sufficient\": False,\n",
    "    \"final_answer\": \"\"\n",
    "}\n",
    "\n",
    "result_run = workflow.run(initial_state)\n",
    "print(f\"Final Answer: {result_run.get_final_state()['final_answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24ad1de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== RUN 2: RAG Query ===\n",
      "[StateMachine] Starting: __entry__\n",
      "   [Step] Check Long Term Memory for user context...('When was San Andreas released?',)\n",
      "   [Step] Checking Memory for user: test_user_1\n",
      "   [Step] prepare return info context memory... ['- open-world games like GTA', '- open-world games like GTA']\n",
      "   [Step] prepare return info context memory...\n",
      "[StateMachine] Executing step: retrieve_memory\n",
      "   [step] Retrieving Game Info...\n",
      "[StateMachine] Executing step: retrieve_game\n",
      "   [Step] Evaluating Context....\n",
      "   [Step] Evaluation Result: True\n",
      "[StateMachine] Executing step: evaluate\n",
      "   [Step] Generating Answer...\n",
      "[StateMachine] Executing step: generate\n",
      "   [Step] Checking for new memories...\n",
      "[StateMachine] Executing step: memorize\n",
      "[StateMachine] Terminating: __termination__\n",
      "Final Answer: Grand Theft Auto: San Andreas was released on PlayStation 2 in 2004.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n=== RUN 2: RAG Query ===\")\n",
    "initial_state_2 = {\n",
    "    \"input_query\": \"When was San Andreas released?\",\n",
    "    \"user_id\": \"test_user_1\",\n",
    "    \"context_games\": None,\n",
    "    \"context_memory\": None,\n",
    "    \"context_web\": None,\n",
    "    \"is_sufficient\": False,\n",
    "    \"final_answer\": \"\"\n",
    "}\n",
    "result_run_2 = workflow.run(initial_state_2)\n",
    "print(f\"Final Answer: {result_run_2.get_final_state()['final_answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc15acf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== RUN 3: Web Search Query ===\n",
      "[StateMachine] Starting: __entry__\n",
      "   [Step] Check Long Term Memory for user context...('What is the latest Cyberpunk 2077 DLC?',)\n",
      "   [Step] Checking Memory for user: test_user_1\n",
      "   [Step] prepare return info context memory... ['- open-world games like GTA', '- open-world games like GTA']\n",
      "   [Step] prepare return info context memory...\n",
      "[StateMachine] Executing step: retrieve_memory\n",
      "   [step] Retrieving Game Info...\n",
      "[StateMachine] Executing step: retrieve_game\n",
      "   [Step] Evaluating Context....\n",
      "   [Step] Evaluation Result: False\n",
      "[StateMachine] Executing step: evaluate\n",
      "   [Step] Searching Web...\n",
      "[StateMachine] Executing step: web_search\n",
      "   [Step] Generating Answer...\n",
      "[StateMachine] Executing step: generate\n",
      "   [Step] Checking for new memories...\n",
      "[StateMachine] Executing step: memorize\n",
      "[StateMachine] Terminating: __termination__\n",
      "Final Answer: The latest DLC for Cyberpunk 2077 is called \"Phantom Liberty,\" which was released on September 25, 2023. This expansion introduces a new spy-thriller storyline and features the return of Keanu Reeves as Johnny Silverhand. It is available for PS5, Xbox Series X|S, and PC.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n=== RUN 3: Web Search Query ===\")\n",
    "initial_state_3 = {\n",
    "    \"input_query\": \"What is the latest Cyberpunk 2077 DLC?\",\n",
    "    \"user_id\": \"test_user_1\",\n",
    "    \"context_games\": None,\n",
    "    \"context_memory\": None,\n",
    "    \"context_web\": None,\n",
    "    \"is_sufficient\": False,\n",
    "    \"final_answer\": \"\"\n",
    "}\n",
    "result_run_3 = workflow.run(initial_state_3)\n",
    "print(f\"Final Answer: {result_run_3.get_final_state()['final_answer']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0 (main, Dec  3 2024, 02:24:14) [GCC 10.2.1 20210110]"
  },
  "vscode": {
   "interpreter": {
    "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
