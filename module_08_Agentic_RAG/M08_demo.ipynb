{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "796124ec",
   "metadata": {},
   "source": [
    "# Module 08: Agentic RAG\n",
    "This notebook demonstrates how traditional Chroma DB works for RAG pipelines.\n",
    "\n",
    "## What we'll learn:\n",
    "- ChromaDB\n",
    "- OpenAI Embeddings\n",
    "- RAG using State Machine\n",
    "- Retrieval, Augment and Generation as steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da7e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca83ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.api.models.Collection import Collection\n",
    "import pdfplumber\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, List\n",
    "\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination, Resource\n",
    "from lib.llm import LLM\n",
    "from lib.messages import BaseMessage, UserMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c4424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('pdfminer').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2744c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv,dotenv_values\n",
    "load_dotenv(dotenv_path=\".env\") # I added the dotenv_path parameter as a reminder for myself that can pass something here if needed... ex. \"../../../.env\"\n",
    "config = dotenv_values() # could have also used os.environ.get(\"UDACITY_OPENAI_API_KEY\") I think, but I like the config approach better\n",
    "api_key = config.get(\"UDACITY_OPENAI_API_KEY\")\n",
    "base_url = config.get(\"BASE_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606d2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [\n",
    "    \"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\",\n",
    "    \"Chip giant Nvidia acquires OctoAI, a Seattle startup that helps companies run AI models\",\n",
    "    \"Google is bringing Gemini to all older Pixel Buds\",\n",
    "    \"The first Intel Battlmage GPU benchmarks have leaked\",\n",
    "    \"Dell partners with Nvidia to accelerate AI adoption in telecoms\",\n",
    "]\n",
    "ids = [\"id1\", \"id2\", \"id3\", \"id4\", \"id5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7858167",
   "metadata": {},
   "source": [
    "## ChromaDB with Default Embedding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bff2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75924db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(\n",
    "    name=\"demo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b4d5903",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=sentence_list,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e79ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26202218",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.peek(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a4c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"gadget\"],\n",
    "    n_results=2,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9bdc20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Google is bringing Gemini to all older Pixel Buds',\n",
       " \"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = collection.query(\n",
    "    query_texts=[\"gadget\"],\n",
    "    n_results=2,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")\n",
    "\n",
    "result['documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1044d051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n"
     ]
    }
   ],
   "source": [
    "print(collection._embedding_function.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e96ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the embeddings array: 384\n"
     ]
    }
   ],
   "source": [
    "size = len(collection.peek(1)['embeddings'][0])\n",
    "print(f\"Size of the embeddings array: {size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239cbe2d",
   "metadata": {},
   "source": [
    "## OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00b29b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.delete_collection(name=\"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d0982f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=api_key,\n",
    "    api_base= base_url\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6130e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(\n",
    "    name=\"demo\",\n",
    "    embedding_function=embeddings_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16673d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=sentence_list,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62c86941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id3', 'id4']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Google is bringing Gemini to all older Pixel Buds',\n",
       "   'The first Intel Battlmage GPU benchmarks have leaked']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None]],\n",
       " 'distances': [[0.46601054072380066, 0.48678600788116455]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"gadget\"],\n",
    "    n_results=2,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70061e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai\n"
     ]
    }
   ],
   "source": [
    "print(collection._embedding_function.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a68ec6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the embeddings array: 1536\n"
     ]
    }
   ],
   "source": [
    "size = len(collection.peek(1)['embeddings'][0])\n",
    "print(f\"Size of the embeddings array: {size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66872a7",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c04c9",
   "metadata": {},
   "source": [
    "**Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16137bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"GlobalEVOutlook2025.pdf\"\n",
    "documents = []\n",
    "page_nums = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be5f6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pdfplumber.open(file_path) as pdf:\n",
    "    for num, page in enumerate(pdf.pages, start=1):\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            documents.append(text)\n",
    "            page_nums.append(str(num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6d1d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(\n",
    "    name=\"traditional_rag\",\n",
    "    embedding_function=embeddings_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2273128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=documents,\n",
    "    ids=page_nums\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb87904",
   "metadata": {},
   "source": [
    "**State Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bcdcb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    question: str\n",
    "    documents: List[str]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be570fcc",
   "metadata": {},
   "source": [
    "**RAG: Retrieve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5d0d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state:State, resource:Resource):\n",
    "    question = state[\"question\"]\n",
    "    collection:Collection = resource.vars.get(\"collection\")\n",
    "    results = collection.query(\n",
    "        query_texts=[question],\n",
    "        n_results=3,\n",
    "        include=['documents']\n",
    "    )\n",
    "    retrieved_docs = results['documents'][0]\n",
    "    \n",
    "    return {\"documents\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b60429f",
   "metadata": {},
   "source": [
    "**RAG: Augment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73a17a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(state:State):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    context = \"\\n\\n\".join(documents)\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an assistant for question-answering tasks.\"),\n",
    "        UserMessage(\n",
    "            content=(\n",
    "                \"Use the following pieces of retrieved context to answer the question. \"\n",
    "                \"If you don't know the answer, just say that you don't know. \"\n",
    "                f\"\\n# Question: \\n-> {question} \"\n",
    "                f\"\\n# Context: \\n-> {context} \"\n",
    "                \"\\n# Answer: \"\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2e9be5",
   "metadata": {},
   "source": [
    "**RAG: Generate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b06ee61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state:State, resource:Resource):\n",
    "    llm:LLM = resource.vars.get(\"llm\")\n",
    "    ai_message = llm.invoke(state[\"messages\"])\n",
    "    return {\n",
    "        \"answer\": ai_message.content, \n",
    "        \"messages\": state[\"messages\"] + [ai_message],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a3c7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateMachine(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f8d12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create steps\n",
    "entry = EntryPoint()\n",
    "retrieve_step = Step(\"retrieve\", retrieve)\n",
    "augment_step = Step(\"augment\", augment)\n",
    "generate_step = Step(\"generate\", generate)\n",
    "termination = Termination()\n",
    "        \n",
    "workflow.add_steps(\n",
    "    [\n",
    "        entry, \n",
    "        retrieve_step, \n",
    "        augment_step, \n",
    "        generate_step, \n",
    "        termination\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adf846ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transitions\n",
    "workflow.connect(entry, retrieve_step)\n",
    "workflow.connect(retrieve_step, augment_step)\n",
    "workflow.connect(augment_step, generate_step)\n",
    "workflow.connect(generate_step, termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "039f9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.3,\n",
    "    api_key=api_key,\n",
    "    base_url=base_url,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a656f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource = Resource(\n",
    "    vars = {\n",
    "        \"llm\": llm,\n",
    "        \"collection\": collection,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c53eb1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state: State = {\n",
    "    \"question\": \"What was the number of electric car sales and their market share in Brazil in 2024?\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1e9954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: augment\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n"
     ]
    }
   ],
   "source": [
    "run_object = workflow.run(initial_state, resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9231fad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In 2024, Brazil had nearly 125,000 electric car sales, which represented a market share of 6.5%.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_object.get_final_state()[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c70358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0 (main, Dec  3 2024, 02:24:14) [GCC 10.2.1 20210110]"
  },
  "vscode": {
   "interpreter": {
    "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
