{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "796124ec",
   "metadata": {},
   "source": [
    "# Module 08: Agentic RAG\n",
    "This notebook demonstrates how traditional Chroma DB works for RAG pipelines.\n",
    "\n",
    "## What we'll learn:\n",
    "- ChromaDB\n",
    "- OpenAI Embeddings\n",
    "- RAG using State Machine\n",
    "- Retrieval, Augment and Generation as steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7da7e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed for Udacity workspace\n",
    "\n",
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "# Check if 'pysqlite3' is available before importing\n",
    "if importlib.util.find_spec(\"pysqlite3\") is not None:\n",
    "    import pysqlite3\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca83ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.api.models.Collection import Collection\n",
    "import pdfplumber\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, List\n",
    "\n",
    "from lib.state_machine import StateMachine, Step, EntryPoint, Termination, Resource\n",
    "from lib.llm import LLM\n",
    "from lib.messages import BaseMessage, UserMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c4424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('pdfminer').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2744c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv,dotenv_values\n",
    "load_dotenv(dotenv_path=\".env\") # I added the dotenv_path parameter as a reminder for myself that can pass something here if needed... ex. \"../../../.env\"\n",
    "config = dotenv_values() # could have also used os.environ.get(\"UDACITY_OPENAI_API_KEY\") I think, but I like the config approach better\n",
    "api_key = config.get(\"UDACITY_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "606d2b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [\n",
    "    \"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\",\n",
    "    \"Chip giant Nvidia acquires OctoAI, a Seattle startup that helps companies run AI models\",\n",
    "    \"Google is bringing Gemini to all older Pixel Buds\",\n",
    "    \"The first Intel Battlmage GPU benchmarks have leaked\",\n",
    "    \"Dell partners with Nvidia to accelerate AI adoption in telecoms\",\n",
    "]\n",
    "ids = [\"id1\", \"id2\", \"id3\", \"id4\", \"id5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7858167",
   "metadata": {},
   "source": [
    "## ChromaDB with Default Embedding Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bff2de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75924db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(\n",
    "    name=\"demo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b4d5903",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:01<00:00, 81.5MiB/s]\n"
     ]
    }
   ],
   "source": [
    "collection.add(\n",
    "    documents=sentence_list,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e79ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26202218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': ['id1'],\n",
       " 'embeddings': array([[ 6.06655143e-02, -3.51322778e-02,  6.06436618e-02,\n",
       "         -5.11926189e-02,  1.13580175e-01, -1.88892670e-02,\n",
       "         -2.68528406e-02,  5.48633598e-02,  3.23644355e-02,\n",
       "          5.42442687e-02, -4.04198617e-02, -1.90558787e-02,\n",
       "         -5.97919673e-02,  2.56031975e-02,  8.48459899e-02,\n",
       "          4.12196591e-02,  3.95206511e-02, -4.00091261e-02,\n",
       "         -7.66606331e-02,  2.78291814e-02,  5.38355038e-02,\n",
       "         -1.35247614e-02,  9.65649858e-02, -3.04361209e-02,\n",
       "          6.61457935e-03,  7.21731111e-02, -9.53866243e-02,\n",
       "         -2.75959149e-02,  7.86794722e-03, -6.68520033e-02,\n",
       "         -1.27341738e-02,  1.21337980e-01, -6.66138455e-02,\n",
       "         -3.28670703e-02, -6.49284497e-02, -1.61902495e-02,\n",
       "         -3.32964119e-03,  8.04081038e-02, -3.84503826e-02,\n",
       "          1.37262192e-04,  3.72601603e-03,  4.83831093e-02,\n",
       "         -3.68634346e-06, -4.51370478e-02, -1.37449540e-02,\n",
       "         -7.15254843e-02,  1.01805590e-02, -4.23029736e-02,\n",
       "          3.16683911e-02,  1.55983735e-02, -3.97931151e-02,\n",
       "         -5.78960925e-02, -6.40797103e-03,  5.05230688e-02,\n",
       "          1.33638009e-02, -6.78851455e-02,  1.05864210e-02,\n",
       "         -4.71997820e-02,  2.75701983e-03,  6.26822188e-02,\n",
       "          3.98217738e-02,  2.90144538e-03, -1.10629732e-02,\n",
       "         -3.56735699e-02,  1.66206166e-01,  2.18000223e-05,\n",
       "         -9.47267562e-03, -1.11342601e-01,  2.20047385e-02,\n",
       "         -5.18188998e-02, -1.24159409e-03, -1.01766661e-02,\n",
       "          2.69736741e-02,  4.42355275e-02, -6.56566173e-02,\n",
       "          3.83598395e-02,  4.76824082e-02, -3.88536379e-02,\n",
       "          6.39469177e-02,  2.61559226e-02,  1.20892614e-01,\n",
       "         -9.07306746e-03, -3.85694094e-02,  2.28224266e-02,\n",
       "          5.07763727e-03, -1.89749785e-02, -2.87914332e-02,\n",
       "         -5.56395948e-02, -8.60798173e-03,  5.86404093e-03,\n",
       "          5.63661158e-02,  6.81668567e-03,  4.91599068e-02,\n",
       "          1.10514216e-01, -3.60370614e-02, -2.38150023e-02,\n",
       "         -1.63016226e-02, -3.64761576e-02, -3.18400264e-02,\n",
       "          8.61765817e-02,  3.62225734e-02, -8.32575187e-02,\n",
       "         -3.95189002e-02, -3.90900951e-03,  6.57733949e-03,\n",
       "         -5.79330027e-02,  7.79308155e-02, -2.28360537e-02,\n",
       "         -5.00358790e-02,  6.03722781e-03, -8.09536036e-03,\n",
       "          4.45688777e-02,  4.15954599e-03,  4.67504486e-02,\n",
       "         -4.04252149e-02,  7.59720802e-02,  3.34816165e-02,\n",
       "          2.89951339e-02,  2.71279309e-02,  1.18415887e-02,\n",
       "         -5.04886955e-02, -4.75644618e-02,  4.13297340e-02,\n",
       "         -1.27794920e-02,  9.69002023e-02, -3.82149331e-02,\n",
       "         -8.40063095e-02, -2.62858610e-33,  2.09661704e-02,\n",
       "         -2.21718522e-03, -3.44077684e-02,  3.05706989e-02,\n",
       "          1.03635713e-01, -4.35035266e-02, -2.39832476e-02,\n",
       "          1.93832591e-02, -4.34555449e-02, -4.16072644e-02,\n",
       "         -4.09181938e-02,  1.49112036e-02, -5.59189655e-02,\n",
       "          8.51473957e-02, -5.81934582e-03, -6.91417828e-02,\n",
       "          2.26447191e-02, -4.11436073e-02,  4.50275876e-02,\n",
       "         -5.11199161e-02,  7.75629729e-02,  1.48884635e-02,\n",
       "         -1.96784968e-03,  3.21936011e-02, -6.81291148e-02,\n",
       "          1.49353713e-01,  5.72788194e-02, -1.83642209e-02,\n",
       "          2.92007234e-02,  7.61160180e-02, -1.02901421e-01,\n",
       "         -7.13465130e-03,  3.35425101e-02,  3.48334871e-02,\n",
       "         -1.32392463e-03,  2.54909764e-03, -4.71515693e-02,\n",
       "          2.60245539e-02, -3.65419276e-02, -3.68678980e-02,\n",
       "         -2.72561074e-03,  2.17560772e-02, -1.12910599e-01,\n",
       "         -2.99250204e-02, -2.38774922e-02, -6.51453584e-02,\n",
       "          1.16424344e-03,  1.92630794e-02, -1.62156001e-02,\n",
       "          2.74781734e-02,  5.08512743e-02,  2.73107421e-02,\n",
       "         -2.71649119e-02,  3.59324627e-02, -5.81062287e-02,\n",
       "         -2.63196174e-02,  8.34815204e-03, -2.87827905e-02,\n",
       "          5.10963835e-02,  2.35960074e-02,  1.05895214e-02,\n",
       "         -3.48852091e-02, -2.97376439e-02,  6.21797442e-02,\n",
       "          4.96876091e-02,  2.55151070e-03, -6.37629814e-03,\n",
       "         -1.16777672e-02, -2.02132631e-02, -1.37591166e-02,\n",
       "         -4.81718173e-03,  5.53599633e-02,  9.78669431e-03,\n",
       "         -7.64255822e-02, -7.46815056e-02, -7.68535957e-02,\n",
       "         -1.85833611e-02,  2.22000899e-03,  6.74626604e-02,\n",
       "          2.59041460e-03,  1.15022231e-02,  8.59656632e-02,\n",
       "          1.94986828e-03, -2.49749497e-02, -1.21855699e-02,\n",
       "         -9.39003378e-03,  5.22418804e-02, -6.60095066e-02,\n",
       "         -5.23915924e-02, -1.49592767e-02,  5.78218699e-02,\n",
       "         -4.54940461e-03,  1.08560026e-02, -2.10045073e-02,\n",
       "          3.67957093e-02,  1.63442957e-33, -7.54486918e-02,\n",
       "         -3.71570862e-03, -3.30684520e-02,  2.56322958e-02,\n",
       "         -2.14399174e-02,  4.71693790e-03, -1.03810122e-02,\n",
       "          8.87744576e-02, -2.98751462e-02,  2.86101345e-02,\n",
       "         -2.06580404e-02,  2.60161366e-02, -4.75597009e-02,\n",
       "         -4.82036918e-03,  6.41304478e-02, -5.69466688e-02,\n",
       "          6.49288595e-02, -1.38111874e-01,  5.93989119e-02,\n",
       "         -2.20186007e-03,  9.33877826e-02,  1.50098661e-02,\n",
       "          4.26070439e-03,  3.95669043e-02, -9.17595625e-02,\n",
       "          2.03433186e-02, -2.72352528e-02, -5.06100804e-02,\n",
       "         -1.51934624e-02,  2.40815561e-02,  3.84032950e-02,\n",
       "          3.39478115e-03, -7.48484880e-02, -8.21176246e-02,\n",
       "          4.00837436e-02,  2.33298298e-02, -6.00907989e-02,\n",
       "          5.34814633e-02, -1.25419833e-02,  2.78937556e-02,\n",
       "          3.23283598e-02,  3.38679813e-02, -4.77768481e-02,\n",
       "         -2.36944687e-02, -2.43718438e-02, -1.29209859e-02,\n",
       "         -3.73663865e-02, -7.32498569e-03,  1.32506728e-01,\n",
       "          1.91215258e-02,  6.31476119e-02, -1.37641534e-01,\n",
       "          2.43645180e-02, -8.76890495e-02,  1.23712588e-02,\n",
       "         -6.28762618e-02,  3.14167961e-02, -3.93745117e-02,\n",
       "         -4.52678576e-02,  7.16478676e-02,  2.08713319e-02,\n",
       "         -5.34157753e-02, -1.12925671e-01, -1.13975391e-01,\n",
       "          4.04910259e-02,  1.17943242e-01,  1.55131957e-02,\n",
       "         -2.58247852e-02,  1.85811613e-02, -1.60459224e-02,\n",
       "          4.09773439e-02, -2.11307849e-03, -8.62064213e-02,\n",
       "         -1.21933796e-01, -4.25355742e-03,  7.11879134e-02,\n",
       "         -5.73185757e-02,  2.77414415e-02,  4.37273905e-02,\n",
       "         -1.63027029e-02,  7.85876531e-03, -1.62124357e-04,\n",
       "          1.68788265e-02, -4.39421013e-02, -1.87048770e-03,\n",
       "         -2.03024447e-02, -6.98395353e-03,  1.07339188e-01,\n",
       "         -2.07637735e-02,  5.85731603e-02,  3.52922119e-02,\n",
       "          5.86631745e-02,  9.77352355e-03,  5.34894690e-02,\n",
       "          1.68920439e-02, -2.19190550e-08, -2.95748599e-02,\n",
       "         -3.72208729e-02, -3.73911895e-02,  9.28657278e-02,\n",
       "          5.08170947e-02,  4.79652584e-02, -2.35483870e-02,\n",
       "          4.04021144e-02,  1.42101496e-01,  2.74159089e-02,\n",
       "          4.89008576e-02, -3.25186811e-02, -3.06229908e-02,\n",
       "          7.28012323e-02,  9.97486115e-02,  8.45944323e-03,\n",
       "         -1.95342526e-02,  1.80620197e-02, -6.47281408e-02,\n",
       "         -7.73269758e-02, -5.81529178e-02,  5.26531320e-03,\n",
       "          9.64109674e-02, -1.43653944e-01,  1.17098885e-02,\n",
       "          1.02300551e-02, -1.01575784e-01,  2.90962476e-02,\n",
       "          2.15431787e-02,  6.96387440e-02, -4.70430031e-02,\n",
       "         -1.47150215e-02, -3.34388763e-02, -1.19946990e-02,\n",
       "         -5.77424988e-02,  3.00530018e-03, -1.48846051e-02,\n",
       "         -3.33915837e-02, -1.70223601e-02, -2.78872233e-02,\n",
       "          8.31423476e-02, -4.47395742e-02, -1.68330539e-02,\n",
       "          4.41734158e-02, -4.54891063e-02, -1.81376878e-02,\n",
       "         -8.59706476e-02,  4.01948998e-03, -3.17578427e-02,\n",
       "         -3.56253120e-03, -7.62893539e-03, -6.97051510e-02,\n",
       "         -1.55669386e-02,  1.00138322e-01,  5.05657829e-02,\n",
       "          3.08241099e-02, -1.35543216e-02,  2.54797265e-02,\n",
       "          5.19400910e-02,  1.28922972e-03,  6.60767406e-02,\n",
       "         -2.51749456e-02, -9.04038325e-02,  5.78943677e-02]]),\n",
       " 'documents': [\"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\"],\n",
       " 'uris': None,\n",
       " 'included': ['embeddings', 'metadatas', 'documents'],\n",
       " 'data': None,\n",
       " 'metadatas': [None]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.peek(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2a4c9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id3', 'id1']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Google is bringing Gemini to all older Pixel Buds',\n",
       "   \"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\"]],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None]],\n",
       " 'distances': [[1.5251753330230713, 1.7548508644104004]]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"gadget\"],\n",
    "    n_results=2,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9bdc20e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Google is bringing Gemini to all older Pixel Buds',\n",
       " \"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = collection.query(\n",
    "    query_texts=[\"gadget\"],\n",
    "    n_results=2,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")\n",
    "\n",
    "result['documents'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1044d051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default\n"
     ]
    }
   ],
   "source": [
    "print(collection._embedding_function.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e96ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the embeddings array: 384\n"
     ]
    }
   ],
   "source": [
    "size = len(collection.peek(1)['embeddings'][0])\n",
    "print(f\"Size of the embeddings array: {size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239cbe2d",
   "metadata": {},
   "source": [
    "## OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00b29b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.delete_collection(name=\"demo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d0982f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'baseUrl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m embeddings_fn = embedding_functions.OpenAIEmbeddingFunction(\n\u001b[32m      2\u001b[39m     api_key=api_key,\n\u001b[32m      3\u001b[39m     config= {\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         \u001b[43mbaseUrl\u001b[49m:\u001b[33m\"\u001b[39m\u001b[33mhttps://openai.vocareum.com/v1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m     }\n\u001b[32m      6\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'baseUrl' is not defined"
     ]
    }
   ],
   "source": [
    "embeddings_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=api_key,\n",
    "    config= {\n",
    "        baseUrl:\"https://openai.vocareum.com/v1\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6130e20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(\n",
    "    name=\"demo\",\n",
    "    embedding_function=embeddings_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16673d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=sentence_list,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62c86941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['id3', 'id4']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['Google is bringing Gemini to all older Pixel Buds',\n",
       "   'The first Intel Battlmage GPU benchmarks have leaked']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[None, None]],\n",
       " 'distances': [[0.46601054072380066, 0.48678600788116455]]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"gadget\"],\n",
    "    n_results=2,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70061e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai\n"
     ]
    }
   ],
   "source": [
    "print(collection._embedding_function.name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a68ec6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the embeddings array: 1536\n"
     ]
    }
   ],
   "source": [
    "size = len(collection.peek(1)['embeddings'][0])\n",
    "print(f\"Size of the embeddings array: {size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c66872a7",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c04c9",
   "metadata": {},
   "source": [
    "**Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16137bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"GlobalEVOutlook2025.pdf\"\n",
    "documents = []\n",
    "page_nums = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be5f6c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pdfplumber.open(file_path) as pdf:\n",
    "    for num, page in enumerate(pdf.pages, start=1):\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            documents.append(text)\n",
    "            page_nums.append(str(num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6d1d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(\n",
    "    name=\"traditional_rag\",\n",
    "    embedding_function=embeddings_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2273128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=documents,\n",
    "    ids=page_nums\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb87904",
   "metadata": {},
   "source": [
    "**State Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bcdcb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    question: str\n",
    "    documents: List[str]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be570fcc",
   "metadata": {},
   "source": [
    "**RAG: Retrieve**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5d0d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state:State, resource:Resource):\n",
    "    question = state[\"question\"]\n",
    "    collection:Collection = resource.vars.get(\"collection\")\n",
    "    results = collection.query(\n",
    "        query_texts=[question],\n",
    "        n_results=3,\n",
    "        include=['documents']\n",
    "    )\n",
    "    retrieved_docs = results['documents'][0]\n",
    "    \n",
    "    return {\"documents\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b60429f",
   "metadata": {},
   "source": [
    "**RAG: Augment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73a17a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(state:State):\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    context = \"\\n\\n\".join(documents)\n",
    "\n",
    "    messages = [\n",
    "        SystemMessage(content=\"You are an assistant for question-answering tasks.\"),\n",
    "        UserMessage(\n",
    "            content=(\n",
    "                \"Use the following pieces of retrieved context to answer the question. \"\n",
    "                \"If you don't know the answer, just say that you don't know. \"\n",
    "                f\"\\n# Question: \\n-> {question} \"\n",
    "                f\"\\n# Context: \\n-> {context} \"\n",
    "                \"\\n# Answer: \"\n",
    "            )\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2e9be5",
   "metadata": {},
   "source": [
    "**RAG: Generate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b06ee61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(state:State, resource:Resource):\n",
    "    llm:LLM = resource.vars.get(\"llm\")\n",
    "    ai_message = llm.invoke(state[\"messages\"])\n",
    "    return {\n",
    "        \"answer\": ai_message.content, \n",
    "        \"messages\": state[\"messages\"] + [ai_message],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a3c7b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateMachine(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f8d12dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create steps\n",
    "entry = EntryPoint()\n",
    "retrieve_step = Step(\"retrieve\", retrieve)\n",
    "augment_step = Step(\"augment\", augment)\n",
    "generate_step = Step(\"generate\", generate)\n",
    "termination = Termination()\n",
    "        \n",
    "workflow.add_steps(\n",
    "    [\n",
    "        entry, \n",
    "        retrieve_step, \n",
    "        augment_step, \n",
    "        generate_step, \n",
    "        termination\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adf846ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add transitions\n",
    "workflow.connect(entry, retrieve_step)\n",
    "workflow.connect(retrieve_step, augment_step)\n",
    "workflow.connect(augment_step, generate_step)\n",
    "workflow.connect(generate_step, termination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "039f9b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LLM(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a656f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "resource = Resource(\n",
    "    vars = {\n",
    "        \"llm\": llm,\n",
    "        \"collection\": collection,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c53eb1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state: State = {\n",
    "    \"question\": \"What was the number of electric car sales and their market share in Brazil in 2024?\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c1e9954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StateMachine] Starting: __entry__\n",
      "[StateMachine] Executing step: retrieve\n",
      "[StateMachine] Executing step: augment\n",
      "[StateMachine] Executing step: generate\n",
      "[StateMachine] Terminating: __termination__\n"
     ]
    }
   ],
   "source": [
    "run_object = workflow.run(initial_state, resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9231fad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In 2024, Brazil had nearly 125,000 electric car sales, which represented a market share of 6.5%.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_object.get_final_state()[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c70358",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0 (main, Dec  3 2024, 02:24:14) [GCC 10.2.1 20210110]"
  },
  "vscode": {
   "interpreter": {
    "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
