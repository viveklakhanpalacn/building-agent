{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tools\n",
    "This notebook demonstrates how we can use tools to gather information and provide more accurate responses. We'll build a weather-checking mock as an example.\n",
    "\n",
    "## What we'll learn:\n",
    "- Basic interaction with Language Models (LLM)\n",
    "- How to create and use tools with AI\n",
    "- The complete flow of an AI agent using tools\n",
    "- Understanding the message flow in a tool-enabled conversation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage  # Different message types\n",
    "from lib.tooling import tool  # Tool decorator for creating AI tools\n",
    "from lib.llm import LLM  # Our Language Model wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = LLM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic LLM Interaction\n",
    "Before we dive into tools, let's understand how to interact with our Language Model in its simplest form. \n",
    "There are two main ways to communicate with the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Query Response:\n",
      " An AI agent is a system or entity that uses artificial intelligence techniques to perceive its environment, make decisions, and take actions to achieve specific goals. AI agents can operate autonomously or semi-autonomously and can be found in various applications, ranging from simple rule-based systems to complex machine learning models.\n",
      "\n",
      "Key characteristics of AI agents include:\n",
      "\n",
      "1. **Perception**: AI agents can gather information from their environment through sensors or data inputs. This could involve processing visual data, audio signals, or other forms of input.\n",
      "\n",
      "2. **Decision-Making**: Based on the information they perceive, AI agents can analyze the data and make decisions. This can involve reasoning, planning, and learning from past experiences.\n",
      "\n",
      "3. **Action**: After making decisions, AI agents can take actions to interact with their environment. This could involve physical actions (like a robot moving) or digital actions (like sending a message or modifying data).\n",
      "\n",
      "4. **Autonomy**: Many AI agents operate with a degree of autonomy, meaning they can perform tasks without human intervention. However, some may require human oversight or input.\n",
      "\n",
      "5. **Adaptability**: Advanced AI agents can learn from their experiences and adapt their behavior over time, improving their performance in specific tasks.\n",
      "\n",
      "AI agents can be categorized into different types, such as:\n",
      "\n",
      "- **Reactive Agents**: These agents respond to specific stimuli in their environment without maintaining an internal state or memory.\n",
      "- **Deliberative Agents**: These agents maintain an internal model of the world and can plan and reason about their actions.\n",
      "- **Learning Agents**: These agents can improve their performance over time by learning from data and experiences.\n",
      "\n",
      "Examples of AI agents include virtual assistants (like Siri or Alexa), autonomous vehicles, recommendation systems, and chatbots. Each of these agents uses AI techniques to perform tasks and interact with users or their environment effectively.\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Simple single-turn query\n",
    "response = chat_model.invoke(\"What is an AI Agent?\")\n",
    "print(\"Single Query Response:\\n\", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Structured Conversation Response:\n",
      " Function calling is a programming concept where a specific function (a block of code designed to perform a particular task) is executed or invoked within a program. When a function is called, the program temporarily transfers control to that function, executes its code, and then returns control back to the point where the function was called, often with a result or output.\n",
      "\n",
      "### Key Concepts of Function Calling:\n",
      "\n",
      "1. **Function Definition**: Before a function can be called, it must be defined. This includes specifying the function's name, parameters (if any), and the code that will be executed.\n",
      "\n",
      "   ```python\n",
      "   def add(a, b):\n",
      "       return a + b\n",
      "   ```\n",
      "\n",
      "2. **Function Call**: To execute the function, you use its name followed by parentheses. If the function requires parameters, you provide them within the parentheses.\n",
      "\n",
      "   ```python\n",
      "   result = add(5, 3)  # This calls the add function with 5 and 3 as arguments.\n",
      "   ```\n",
      "\n",
      "3. **Return Value**: Functions can return values using the `return` statement. The value returned can be stored in a variable or used directly.\n",
      "\n",
      "4. **Parameters and Arguments**: Parameters are the variables listed in a function's definition, while arguments are the actual values passed to the function when it is called.\n",
      "\n",
      "5. **Scope**: Variables defined within a function are typically local to that function and cannot be accessed outside of it, unless they are returned or defined as global.\n",
      "\n",
      "6. **Recursion**: A function can call itself, which is known as recursion. This is often used for problems that can be broken down into smaller, similar problems.\n",
      "\n",
      "### Example in Python:\n",
      "\n",
      "```python\n",
      "def greet(name):\n",
      "    return f\"Hello, {name}!\"\n",
      "\n",
      "# Function call\n",
      "message = greet(\"Alice\")\n",
      "print(message)  # Output: Hello, Alice!\n",
      "```\n",
      "\n",
      "In this example, the `greet` function is defined to take one parameter, `name`, and returns a greeting message. The function is then called with the argument \"Alice\", and the result is printed.\n",
      "\n",
      "Function calling is a fundamental aspect of programming that helps in organizing code, promoting reusability, and improving readability.\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Multi-turn conversation with specific roles\n",
    "messages = [\n",
    "    SystemMessage(content=\"You're an OpenAI API specialist\"),\n",
    "    UserMessage(content=\"What is Function Calling?\")\n",
    "]\n",
    "response = chat_model.invoke(messages)\n",
    "print(\"\\nStructured Conversation Response:\\n\", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an AI Tool\n",
    "Now let's make our AI more capable by giving it a tool to check the weather. \n",
    "This demonstrates how we can extend AI capabilities beyond just conversation.\n",
    "\n",
    "### Understanding the Tool Structure:\n",
    "1. We use the `@tool` decorator to mark a function as an AI tool\n",
    "2. The tool needs clear documentation and typed parameters\n",
    "3. The tool should return structured data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_weather(city: str):\n",
    "    \"\"\"Get the current temperature for a city.\n",
    "    \n",
    "    Args:\n",
    "        city (str): Name of the city to check weather for\n",
    "        \n",
    "    Returns:\n",
    "        dict: Contains temperature information for the requested city\n",
    "    \"\"\"\n",
    "    # In a real application, this would call a weather API\n",
    "    mock_weather = {\n",
    "        \"São Paulo\": \"28°C\",\n",
    "        \"Oslo\": \"-3°C\",\n",
    "        \"New York\": \"15°C\",\n",
    "        \"Tokyo\": \"22°C\"\n",
    "    }\n",
    "    return {\"temperature\": mock_weather.get(city, \"Unknown\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind the tool to an LLM\n",
    "chat_model_with_tools = LLM(tools=[get_weather])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Tool Usage Flow\n",
    "Let's break down how the AI uses tools step by step:\n",
    "\n",
    "1. User asks a question about weather\n",
    "2. AI recognizes the need to use the weather tool\n",
    "3. AI makes a tool call\n",
    "4. Tool executes and returns results\n",
    "5. AI processes the tool's response\n",
    "6. AI formulates a natural language response\n",
    "\n",
    "Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our system with clear instructions\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that can access a tool to get current temperature \" \n",
    "                \"for cities. Use the tool whenever someone asks about the weather or temperature \" \n",
    "                \"in a specific location. Infor the user if you don't know the answer.\"\n",
    "    ),\n",
    "    UserMessage(content=\"How cold is it in Oslo?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(id='call_alIVgyMRCmiOm7S2PeUxXKjq', function=Function(arguments='{\"city\":\"Oslo\"}', name='get_weather'), type='function')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AI decides to use the weather tool\n",
    "ai_message = chat_model_with_tools.invoke(messages)\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You are a helpful assistant that can access a tool to get current temperature for cities. Use the tool whenever someone asks about the weather or temperature in a specific location. Infor the user if you don't know the answer.\", role='system'),\n",
       " UserMessage(content='How cold is it in Oslo?', role='user'),\n",
       " AIMessage(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(id='call_alIVgyMRCmiOm7S2PeUxXKjq', function=Function(arguments='{\"city\":\"Oslo\"}', name='get_weather'), type='function')])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check messages structure\n",
    "messages.append(ai_message)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call_alIVgyMRCmiOm7S2PeUxXKjq'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tool call id will be required later when creating the ToolMessage\n",
    "tool_call_id = messages[-1].tool_calls[0].id\n",
    "tool_call_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'city': 'Oslo'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the arguments\n",
    "args = json.loads(messages[-1].tool_calls[0].function.arguments)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temperature': '-3°C'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the tool with the AI's requested parameters\n",
    "tool_result = get_weather(**args)\n",
    "tool_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToolMessage(content='-3°C', role='tool', tool_call_id='call_alIVgyMRCmiOm7S2PeUxXKjq', name='get_weather')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tool response message\n",
    "tool_message = ToolMessage(\n",
    "    content=tool_result[\"temperature\"], \n",
    "    tool_call_id=tool_call_id, \n",
    "    name=\"get_weather\"\n",
    ")\n",
    "tool_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You are a helpful assistant that can access a tool to get current temperature for cities. Use the tool whenever someone asks about the weather or temperature in a specific location. Infor the user if you don't know the answer.\", role='system'),\n",
       " UserMessage(content='How cold is it in Oslo?', role='user'),\n",
       " AIMessage(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(id='call_alIVgyMRCmiOm7S2PeUxXKjq', function=Function(arguments='{\"city\":\"Oslo\"}', name='get_weather'), type='function')]),\n",
       " ToolMessage(content='-3°C', role='tool', tool_call_id='call_alIVgyMRCmiOm7S2PeUxXKjq', name='get_weather')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check messages structure\n",
    "messages.append(tool_message)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The current temperature in Oslo is -3°C.', role='assistant', tool_calls=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let AI formulate final response\n",
    "ai_message = chat_model_with_tools.invoke(messages)\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"You are a helpful assistant that can access a tool to get current temperature for cities. Use the tool whenever someone asks about the weather or temperature in a specific location. Infor the user if you don't know the answer.\", role='system'),\n",
       " UserMessage(content='How cold is it in Oslo?', role='user'),\n",
       " AIMessage(content=None, role='assistant', tool_calls=[ChatCompletionMessageToolCall(id='call_alIVgyMRCmiOm7S2PeUxXKjq', function=Function(arguments='{\"city\":\"Oslo\"}', name='get_weather'), type='function')]),\n",
       " ToolMessage(content='-3°C', role='tool', tool_call_id='call_alIVgyMRCmiOm7S2PeUxXKjq', name='get_weather'),\n",
       " AIMessage(content='The current temperature in Oslo is -3°C.', role='assistant', tool_calls=None)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check messages structure\n",
    "messages.append(ai_message)\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0 (main, Dec  3 2024, 02:24:14) [GCC 10.2.1 20210110]"
  },
  "vscode": {
   "interpreter": {
    "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
