{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "541a5c9c",
   "metadata": {},
   "source": [
    "# [SOLUTION] Exercise - Building an AI Agent with Tools\n",
    "\n",
    "In this exercise, you'll build an AI agent that can use tools to enhance its capabilities. You'll learn how to create an agent that can understand when to use tools, process their results, and maintain a coherent conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918d12a",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "Imagine you're building a smart coding assistant that needs to:\n",
    "- Answer programming questions\n",
    "- Execute code snippets\n",
    "- Look up documentation\n",
    "- Perform calculations\n",
    "- Search through codebases\n",
    "\n",
    "Instead of hard-coding when to use each capability, your agent should intelligently decide when and how to use its available tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9c89db",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, let's import the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a220d2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Any\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "from lib.messages import UserMessage, SystemMessage, ToolMessage\n",
    "from lib.tooling import tool\n",
    "from lib.llm import LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cec412",
   "metadata": {},
   "source": [
    "## Understanding the Components\n",
    "\n",
    "Before we build our agent, let's understand the key components we'll be working with:\n",
    "\n",
    "- `LLM`: The language model wrapper that handles tool execution\n",
    "- `SystemMessage`: Defines the agent's role and behavior\n",
    "- `UserMessage`: Represents user inputs\n",
    "- `ToolMessage`: Contains tool execution results\n",
    "- `tool`: Decorator for creating tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92058e5",
   "metadata": {},
   "source": [
    "## Building the Agent Class\n",
    "\n",
    "Your task is to create an Agent class that can:\n",
    "1. Initialize with a specific role and set of tools\n",
    "2. Process user messages\n",
    "3. Decide when to use tools\n",
    "4. Handle tool responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f95460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\"An AI Agent that can use tools to help answer questions\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        role: str = \"Personal Assistant\",\n",
    "        instructions: str = \"Help users with any question\",\n",
    "        model: str = \"gpt-4o-mini\",\n",
    "        temperature: float = 0.0,\n",
    "        tools: List[Any] = None\n",
    "    ):\n",
    "        \"\"\"Initialize the agent with its configuration and tools\n",
    "        \n",
    "        Args:\n",
    "            role: The agent's role/persona\n",
    "            instructions: Basic instructions for the agent\n",
    "            model: The LLM model to use\n",
    "            temperature: Creativity parameter (0.0 = more 'deterministic')\n",
    "            tools: List of tools the agent can use\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.role = role\n",
    "        self.instructions = instructions\n",
    "        self.tools = tools\n",
    "\n",
    "        # Load environment variables (e.g. API keys)\n",
    "        load_dotenv()\n",
    "        \n",
    "        # Initialize the LLM with tools if provided\n",
    "        self.llm = LLM(\n",
    "            model=model,\n",
    "            temperature=temperature,\n",
    "            tools=tools,\n",
    "        )\n",
    "\n",
    "    def invoke(self, user_message: str) -> str:\n",
    "        \"\"\"Process a user message and return a response\n",
    "        \n",
    "        Args:\n",
    "            user_message: The user's input message\n",
    "            \n",
    "        Returns:\n",
    "            The agent's response after processing tools if needed\n",
    "        \"\"\"\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=(\n",
    "                    f\"You're an AI Agent and your role is {self.role}. \"  \n",
    "                    f\"Your instructions: {self.instructions}\"\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "        # Add user message to conversation\n",
    "        messages.append(UserMessage(content=user_message))\n",
    "        \n",
    "        # Get AI response and add to conversation\n",
    "        ai_message = self.llm.invoke(messages)\n",
    "        messages.append(ai_message)\n",
    "\n",
    "        # Check if tools were required\n",
    "        while ai_message.tool_calls:\n",
    "            # Process each tool call                    \n",
    "            for call in ai_message.tool_calls:\n",
    "                # Access tool call data correctly\n",
    "                function_name = call.function.name\n",
    "                function_args = json.loads(call.function.arguments)\n",
    "                tool_call_id = call.id\n",
    "                # Find the matching tool\n",
    "                tool = next((t for t in self.tools if t.name == function_name), None)\n",
    "                if tool:\n",
    "                    result = tool(**function_args)\n",
    "                    messages.append(\n",
    "                        ToolMessage(\n",
    "                            content=json.dumps(result), \n",
    "                            tool_call_id=tool_call_id, \n",
    "                            name=function_name, \n",
    "                        )\n",
    "                    )\n",
    "                \n",
    "            # Get final AI response after tool usage and add to conversation\n",
    "            ai_message = self.llm.invoke(messages)\n",
    "            messages.append(ai_message)\n",
    "\n",
    "        for m in messages:\n",
    "            print(m)\n",
    "        return ai_message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda3c9b8",
   "metadata": {},
   "source": [
    "## Testing Your Agent\n",
    "\n",
    "Once you've implemented the Agent class, test it with different scenarios:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cef22d6",
   "metadata": {},
   "source": [
    "1. Basic conversation without tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fdf9fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"You're an AI Agent and your role is Coding Assistant. Your instructions: Help users with any question\" role='system'\n",
      "content='What is Python? Be concise' role='user'\n",
      "content='Python is a high-level, interpreted programming language known for its readability and simplicity. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python is widely used for web development, data analysis, artificial intelligence, scientific computing, and automation, among other applications.' role='assistant' tool_calls=None\n",
      "Python is a high-level, interpreted programming language known for its readability and simplicity. It supports multiple programming paradigms, including procedural, object-oriented, and functional programming. Python is widely used for web development, data analysis, artificial intelligence, scientific computing, and automation, among other applications.\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(role=\"Coding Assistant\")\n",
    "response = agent.invoke(\"What is Python? Be concise\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661ec4ce",
   "metadata": {},
   "source": [
    "2. Create a calculator tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c637de",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def calculate(expression: str) -> float:\n",
    "    \"\"\"Evaluate a mathematical expression\"\"\"\n",
    "    return eval(expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3204ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create an agent with the calculator tool\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m math_agent = \u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrole\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMath Assistant\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcalculate\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mAgent.__init__\u001b[39m\u001b[34m(self, role, instructions, model, temperature, tools)\u001b[39m\n\u001b[32m     27\u001b[39m load_dotenv()\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# Initialize the LLM with tools if provided\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28mself\u001b[39m.llm = \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/Code/module_01_Extending_Agents_with_Tools/lib/llm.py:22\u001b[39m, in \u001b[36mLLM.__init__\u001b[39m\u001b[34m(self, model, temperature, tools, api_key)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28mself\u001b[39m.model = model\n\u001b[32m     21\u001b[39m \u001b[38;5;28mself\u001b[39m.temperature = temperature\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m \u001b[38;5;28mself\u001b[39m.client = OpenAI(api_key=api_key) \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mself\u001b[39m.tools: Dict[\u001b[38;5;28mstr\u001b[39m, Tool] = {\n\u001b[32m     24\u001b[39m     tool.name: tool \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m (tools \u001b[38;5;129;01mor\u001b[39;00m [])\n\u001b[32m     25\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/venv/lib/python3.13/site-packages/openai/_client.py:116\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    114\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    117\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    118\u001b[39m     )\n\u001b[32m    119\u001b[39m \u001b[38;5;28mself\u001b[39m.api_key = api_key\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Create an agent with the calculator tool\n",
    "math_agent = Agent(\n",
    "    role=\"Math Assistant\",\n",
    "    tools=[calculate]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "437c9e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"You're an AI Agent and your role is Math Assistant. Your instructions: Help users with any question\" role='system'\n",
      "content='What is 23 * 45?' role='user'\n",
      "content=None role='assistant' tool_calls=[ChatCompletionMessageToolCall(id='call_klzgArJHewvSYoIzGo8IQdJs', function=Function(arguments='{\"expression\":\"23 * 45\"}', name='calculate'), type='function')]\n",
      "content='1035' role='tool' tool_call_id='call_klzgArJHewvSYoIzGo8IQdJs' name='calculate'\n",
      "content='The result of \\\\( 23 \\\\times 45 \\\\) is 1035.' role='assistant' tool_calls=None\n",
      "The result of \\( 23 \\times 45 \\) is 1035.\n"
     ]
    }
   ],
   "source": [
    "response = math_agent.invoke(\"What is 23 * 45?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e1b6096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"You're an AI Agent and your role is Math Assistant. Your instructions: Help users with any question\" role='system'\n",
      "content='If I multiply 3 by 5, what do I get? Then later add 7' role='user'\n",
      "content=None role='assistant' tool_calls=[ChatCompletionMessageToolCall(id='call_ng19o6ZlDmgnlLdU2m3hyqSs', function=Function(arguments='{\"expression\": \"3 * 5\"}', name='calculate'), type='function'), ChatCompletionMessageToolCall(id='call_EVP76gLh7JUWys9uQqyRYQ3c', function=Function(arguments='{\"expression\": \"3 * 5 + 7\"}', name='calculate'), type='function')]\n",
      "content='15' role='tool' tool_call_id='call_ng19o6ZlDmgnlLdU2m3hyqSs' name='calculate'\n",
      "content='22' role='tool' tool_call_id='call_EVP76gLh7JUWys9uQqyRYQ3c' name='calculate'\n",
      "content='If you multiply 3 by 5, you get 15. If you then add 7 to that result, you get 22.' role='assistant' tool_calls=None\n",
      "If you multiply 3 by 5, you get 15. If you then add 7 to that result, you get 22.\n"
     ]
    }
   ],
   "source": [
    "# Test multiple tool usage\n",
    "response = math_agent.invoke(\"If I multiply 3 by 5, what do I get? Then later add 7\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a3a881",
   "metadata": {},
   "source": [
    "3. Create a data analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfb01df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_games(num_games:int=1, top:bool=True) -> str:\n",
    "    \"\"\"\n",
    "    Returns the top or bottom N games with highest or lowest scores.    \n",
    "    args:\n",
    "        num_games (int): Number of games to return (default is 1)\n",
    "        top (bool): If True, return top games, otherwise return bottom (default is True)\n",
    "    \"\"\"\n",
    "    data = [\n",
    "        {\"Game\": \"The Legend of Zelda: Breath of the Wild\", \"Platform\": \"Switch\", \"Score\": 98},\n",
    "        {\"Game\": \"Super Mario Odyssey\", \"Platform\": \"Switch\", \"Score\": 97},\n",
    "        {\"Game\": \"Metroid Prime\", \"Platform\": \"GameCube\", \"Score\": 97},\n",
    "        {\"Game\": \"Super Smash Bros. Brawl\", \"Platform\": \"Wii\", \"Score\": 93},\n",
    "        {\"Game\": \"Mario Kart 8 Deluxe\", \"Platform\": \"Switch\", \"Score\": 92},\n",
    "        {\"Game\": \"Fire Emblem: Awakening\", \"Platform\": \"3DS\", \"Score\": 92},\n",
    "        {\"Game\": \"Donkey Kong Country Returns\", \"Platform\": \"Wii\", \"Score\": 87},\n",
    "        {\"Game\": \"Luigi's Mansion 3\", \"Platform\": \"Switch\", \"Score\": 86},\n",
    "        {\"Game\": \"Pikmin 3\", \"Platform\": \"Wii U\", \"Score\": 85},\n",
    "        {\"Game\": \"Animal Crossing: New Leaf\", \"Platform\": \"3DS\", \"Score\": 88}\n",
    "    ]\n",
    "    # Sort the games list by Score\n",
    "    # If top is True, descending order\n",
    "    sorted_games = sorted(data, key=lambda x: x['Score'], reverse=top)\n",
    "    \n",
    "    # Return the N games\n",
    "    return sorted_games[:num_games]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15908ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent with the multiple tools\n",
    "data_analyst_agent = Agent(\n",
    "    role=\"Game Stats Assistant\",\n",
    "    instructions=\"You can bring insights about a game dataset based on users questions\",\n",
    "    tools=[get_games]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b982bbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"You're an AI Agent and your role is Game Stats Assistant. Your instructions: You can bring insights about a game dataset based on users questions\" role='system'\n",
      "content=\"What's the best game in the dataset?\" role='user'\n",
      "content=None role='assistant' tool_calls=[ChatCompletionMessageToolCall(id='call_lCcYDtEfEHiNd6jSGcv3HlvC', function=Function(arguments='{\"num_games\":1,\"top\":true}', name='get_games'), type='function')]\n",
      "content='[{\"Game\": \"The Legend of Zelda: Breath of the Wild\", \"Platform\": \"Switch\", \"Score\": 98}]' role='tool' tool_call_id='call_lCcYDtEfEHiNd6jSGcv3HlvC' name='get_games'\n",
      "content='The best game in the dataset is \"The Legend of Zelda: Breath of the Wild\" for the Switch, with a score of 98.' role='assistant' tool_calls=None\n",
      "The best game in the dataset is \"The Legend of Zelda: Breath of the Wild\" for the Switch, with a score of 98.\n"
     ]
    }
   ],
   "source": [
    "response = data_analyst_agent.invoke(\"What's the best game in the dataset?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab4f1b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"You're an AI Agent and your role is Game Stats Assistant. Your instructions: You can bring insights about a game dataset based on users questions\" role='system'\n",
      "content=\"What's the worst game in the dataset?\" role='user'\n",
      "content=None role='assistant' tool_calls=[ChatCompletionMessageToolCall(id='call_2gOlDuDgH8YYAB0bRvV4YY5d', function=Function(arguments='{\"num_games\":1,\"top\":false}', name='get_games'), type='function')]\n",
      "content='[{\"Game\": \"Pikmin 3\", \"Platform\": \"Wii U\", \"Score\": 85}]' role='tool' tool_call_id='call_2gOlDuDgH8YYAB0bRvV4YY5d' name='get_games'\n",
      "content='The worst game in the dataset is \"Pikmin 3\" for the Wii U, with a score of 85.' role='assistant' tool_calls=None\n",
      "The worst game in the dataset is \"Pikmin 3\" for the Wii U, with a score of 85.\n"
     ]
    }
   ],
   "source": [
    "response = data_analyst_agent.invoke(\"What's the worst game in the dataset?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf88891d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "23393d2575091a37cff0d0e9e7479591a295495b26c3b2ebf9b64da572e02d85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
